{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chinmayeechintapanti/face_recognition/blob/main/face_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61DKlOfOiHxr",
        "outputId": "3dd94fd0-0fc1-4dbc-c7a5-2dd6c910b99c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.21)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.8)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.15.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9ziQFleiIVg"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Javascript, display\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "    js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'üì∏ Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getTracks().forEach(track => track.stop());\n",
        "      div.remove();\n",
        "\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "    display(js)\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "    return filename\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e9_aE5dijFd"
      },
      "outputs": [],
      "source": [
        "import mediapipe as mp\n",
        "\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "iris_indices = [468, 469, 470, 471, 472, 473, 474, 475]\n",
        "\n",
        "def extract_face_embedding(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    with mp_face_mesh.FaceMesh(static_image_mode=True, refine_landmarks=True) as face_mesh:\n",
        "        results = face_mesh.process(rgb)\n",
        "        if not results.multi_face_landmarks:\n",
        "            return None\n",
        "        landmarks = results.multi_face_landmarks[0]\n",
        "        return np.array([[p.x, p.y, p.z] for p in landmarks.landmark]).flatten()\n",
        "\n",
        "def extract_iris_embedding(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    with mp_face_mesh.FaceMesh(static_image_mode=True, refine_landmarks=True) as face_mesh:\n",
        "        results = face_mesh.process(rgb)\n",
        "        if not results.multi_face_landmarks:\n",
        "            return None\n",
        "        landmarks = results.multi_face_landmarks[0]\n",
        "        iris_data = []\n",
        "        for i in iris_indices:\n",
        "            p = landmarks.landmark[i]\n",
        "            iris_data.extend([p.x, p.y, p.z])\n",
        "        return np.array(iris_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RUw_5lNimwm"
      },
      "outputs": [],
      "source": [
        "def register_user():\n",
        "    os.makedirs(\"users\", exist_ok=True)\n",
        "    username = input(\"Enter a username: \")\n",
        "    password = getpass.getpass(\"Enter a password: \")\n",
        "    path = f'users/{username}.pkl'\n",
        "\n",
        "    if os.path.exists(path):\n",
        "        print(\"‚ùå User already exists.\")\n",
        "        return\n",
        "\n",
        "    print(\"Look into the camera and click 'Capture'\")\n",
        "    photo_path = take_photo()\n",
        "\n",
        "    face_embedding = extract_face_embedding(photo_path)\n",
        "    iris_embedding = extract_iris_embedding(photo_path)\n",
        "\n",
        "    if face_embedding is None or iris_embedding is None:\n",
        "        print(\"‚ùå Could not detect face or iris.\")\n",
        "        return\n",
        "\n",
        "    face_embedding = face_embedding / np.linalg.norm(face_embedding)\n",
        "    iris_embedding = iris_embedding / np.linalg.norm(iris_embedding)\n",
        "\n",
        "    user_data = {\n",
        "        \"username\": username,\n",
        "        \"password\": password,\n",
        "        \"face_embedding\": face_embedding,\n",
        "        \"iris_embedding\": iris_embedding\n",
        "    }\n",
        "\n",
        "    with open(path, 'wb') as f:\n",
        "        pickle.dump(user_data, f)\n",
        "\n",
        "    print(f\"‚úÖ User '{username}' registered successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWIxuPJuszN1"
      },
      "outputs": [],
      "source": [
        "def login_user():\n",
        "    print(\"Look into the camera and click 'Capture' to login.\")\n",
        "    photo_path = take_photo()\n",
        "\n",
        "    face_embedding = extract_face_embedding(photo_path)\n",
        "    iris_embedding = extract_iris_embedding(photo_path)\n",
        "\n",
        "    if face_embedding is None or iris_embedding is None:\n",
        "        print(\"‚ùå Could not detect face or iris.\")\n",
        "        return\n",
        "\n",
        "    face_embedding = face_embedding / np.linalg.norm(face_embedding)\n",
        "    iris_embedding = iris_embedding / np.linalg.norm(iris_embedding)\n",
        "\n",
        "    best_match = None\n",
        "    min_total_dist = float('inf')\n",
        "\n",
        "    for file in os.listdir(\"users\"):\n",
        "        with open(f\"users/{file}\", \"rb\") as f:\n",
        "            user_data = pickle.load(f)\n",
        "\n",
        "        face_dist = np.linalg.norm(user_data[\"face_embedding\"] - face_embedding)\n",
        "        iris_dist = np.linalg.norm(user_data[\"iris_embedding\"] - iris_embedding)\n",
        "        total_dist = face_dist + iris_dist\n",
        "\n",
        "        print(f\"User: {user_data['username']} | Face: {face_dist:.4f} | Iris: {iris_dist:.4f}\")\n",
        "\n",
        "        if total_dist < min_total_dist:\n",
        "            min_total_dist = total_dist\n",
        "            best_match = user_data[\"username\"]\n",
        "\n",
        "    if min_total_dist < 2.0:  # You can adjust this threshold\n",
        "        print(f\"‚úÖ Login successful. Welcome, {best_match}! (Score: {min_total_dist:.4f})\")\n",
        "    else:\n",
        "        print(\"‚ùå Face + iris not recognized.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pickle\n",
        "import getpass\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from IPython.display import Javascript, display, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n"
      ],
      "metadata": {
        "id": "J9Y7GQJzILm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYqc-klns0bg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "5836a574-14fb-47b8-972c-ea7864fd0bc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a username: abc\n",
            "Enter a password: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Look into the camera and click 'Capture'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'üì∏ Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getTracks().forEach(track => track.stop());\n",
              "      div.remove();\n",
              "\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ User 'abc' registered successfully.\n"
          ]
        }
      ],
      "source": [
        "register_user()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXfyPq2rs32N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "216850bd-3e58-4cd0-a8f3-2162a4a14dfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Look into the camera and click 'Capture' to login.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'üì∏ Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getTracks().forEach(track => track.stop());\n",
              "      div.remove();\n",
              "\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: abc | Face: 0.0067 | Iris: 0.0122\n",
            "‚úÖ Login successful. Welcome, abc! (Score: 0.0189)\n"
          ]
        }
      ],
      "source": [
        "login_user()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_3Vhz7stNn1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkiN3eCBo8c+yqbyGjG/ZQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}